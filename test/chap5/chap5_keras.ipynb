{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 15:24:54.074953: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1729970694.094157 2840663 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1729970694.100690 2840663 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-26 15:24:54.122252: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# DNN model definition\n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_layer  = Dense(256, activation='relu', input_shape=(784,))\n",
    "        self.hidden_layer = Dense(128, activation='relu')\n",
    "        self.output_layer = Dense(10, activation='softmax')\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.hidden_layer(x)\n",
    "        output = self.output_layer(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/projects/KeeGroup/ykee/myenv/REINFORCE/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1729970717.966015 2840663 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38487 MB memory:  -> device: 0, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:21:00.0, compute capability: 8.0\n",
      "I0000 00:00:1729970717.968800 2840663 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 38487 MB memory:  -> device: 1, name: NVIDIA A100-PCIE-40GB, pci bus id: 0000:81:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # model, cost function, optimizer\n",
    "    model = Model()\n",
    "    cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "    optimizer = Adam(1e-4)\n",
    "    \n",
    "    # load data\n",
    "    mnist = tf.keras.datasets.fashion_mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    # data preprocessing\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "    \n",
    "    # minibatch size\n",
    "    batch_size = 32\n",
    "    num_train_data = x_train.shape[0]\n",
    "    num_test_data = x_test.shape[0]\n",
    "    \n",
    "    # training\n",
    "    num_epoch = 10\n",
    "    for e in range(num_epoch):\n",
    "        for i in range(num_train_data // batch_size):\n",
    "            x_batch = x_train[i * batch_size : (i + 1) * batch_size]\n",
    "            y_batch = y_train[i * batch_size : (i + 1) * batch_size] \n",
    "        \n",
    "            x_batch = x_batch.reshape(-1, 28 * 28)\n",
    "            y_batch = tf.one_hot(y_batch, 10)\n",
    "        \n",
    "            with tf.GradientTape() as tape:\n",
    "                # prediction\n",
    "                predicts = model(x_batch)\n",
    "                #\n",
    "                model_params = model.trainable_variables\n",
    "                # calculate loss\n",
    "                losses = cross_entropy(predicts, y_batch)\n",
    "            # compute gradient\n",
    "            grads = tape.gradient(losses, model_params)\n",
    "            # model update\n",
    "            optimizer.apply_gradients(zip(grads, model_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8598\n",
      "Predictions: [9 2 1 1 6]\n",
      "True Labels: [9 2 1 1 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# testing\n",
    "# Convert y_test to one-hot if needed\n",
    "y_test_one_hot = tf.one_hot(y_test, 10)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model(x_test.reshape(-1, 28 * 28), training=False)  # Set training=False for inference mode\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_predictions = tf.equal(tf.argmax(predictions, axis=1), tf.argmax(y_test_one_hot, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy.numpy())\n",
    "\n",
    "# Optional: Print predictions for the first 5 test samples for manual verification\n",
    "print(\"Predictions:\", np.argmax(predictions[:5], axis=1))\n",
    "print(\"True Labels:\", y_test[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
